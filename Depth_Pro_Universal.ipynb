{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Depth Pro - AI Depth Map Generator\n",
        "\n",
        "Transform any 2D image into a detailed 3D depth map using **Apple's Depth Pro** model!\n",
        "\n",
        "> **Note:** This is a personal project to try out Apple's ml-depth-pro model. After getting it working locally with easy-to-use scripts, I decided to publish it so anyone else interested can try it too. The core model and logic are from the original Apple repository.\n",
        "\n",
        "## Features\n",
        "- **GPU Accelerated**: Optimized for CUDA with CPU fallback\n",
        "- **Universal**: Works in Google Colab, local Jupyter, or any Python environment\n",
        "- **Metric Depth**: Predicts true, real-world depth and estimates focal length\n",
        "- **Private**: All processing happens in your environment\n",
        "- **Open-Source**: Based on Apple's research, free to use\n",
        "\n",
        "## Research\n",
        "This work is based on the paper \"Depth Pro: Sharp Monocular Metric Depth in Less Than a Second\" (2024) by A. Bochkovskii, A. Delaunoy, H. Germain, M. Santos, Y. Zhou, S. Richter, and V. Koltun.\n",
        "\n",
        "---\n",
        "\n",
        "## 🚀 Quick Start Instructions\n",
        "\n",
        "### For Google Colab:\n",
        "1. Enable GPU: `Runtime` → `Change runtime type` → Set `Hardware accelerator` to `GPU`\n",
        "2. Run all cells: `Runtime` → `Run all` or run cells one by one\n",
        "3. Get a public shareable URL after the last cell runs\n",
        "\n",
        "### For Local Jupyter:\n",
        "1. Make sure you're in the `ml-depth-pro` directory\n",
        "2. Ensure PyTorch with GPU support is installed\n",
        "3. Run all cells to get a local interface at http://127.0.0.1:7860\n",
        "\n",
        "### What This Notebook Does Automatically:\n",
        "- **Environment Detection**: Detects Google Colab vs local environment\n",
        "- **Hardware Optimization**: Uses CUDA GPU → Apple Silicon (MPS) → CPU fallback\n",
        "- **Smart Installation**: Only installs missing packages locally, full setup in Colab\n",
        "- **Launch Configuration**: Public URLs for Colab, local URLs for Jupyter\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 1: Environment Detection & Setup\n",
        "\n",
        "Detecting environment (Google Colab vs Local Jupyter) and setting up accordingly...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import platform\n",
        "\n",
        "# Detect environment\n",
        "def detect_environment():\n",
        "    \"\"\"Detect if running in Google Colab or local environment\"\"\"\n",
        "    try:\n",
        "        import google.colab\n",
        "        return \"colab\"\n",
        "    except ImportError:\n",
        "        return \"local\"\n",
        "\n",
        "ENV = detect_environment()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"DEPTH PRO - UNIVERSAL ENVIRONMENT\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Environment: {ENV.upper()}\")\n",
        "print(f\"Platform: {platform.system()} {platform.machine()}\")\n",
        "print(f\"Python: {sys.version}\")\n",
        "\n",
        "# Check GPU availability\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"PyTorch: {torch.__version__}\")\n",
        "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    \n",
        "    # Check for Apple Silicon (MPS)\n",
        "    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "        print(\"Apple Silicon GPU (MPS) available\")\n",
        "except ImportError:\n",
        "    print(\"PyTorch not installed - will install in next step\")\n",
        "\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 2: Install Dependencies\n",
        "\n",
        "Installing required packages based on the environment...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "print(\"Installing dependencies...\")\n",
        "import subprocess\n",
        "\n",
        "packages = [\n",
        "    'opencv-python-headless',\n",
        "    'timm',\n",
        "    'matplotlib',\n",
        "    'tqdm',\n",
        "    'ipywidgets'  # For interactive file upload widget\n",
        "]\n",
        "\n",
        "if ENV == \"colab\":\n",
        "    # Google Colab - install everything needed\n",
        "    for package in packages:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
        "else:\n",
        "    # Local environment - install only what's missing\n",
        "    for package in packages:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
        "        except subprocess.CalledProcessError:\n",
        "            print(f\"Warning: Could not install {package}\")\n",
        "\n",
        "print(\"Dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 3: Setup Repository\n",
        "\n",
        "Setting up the Depth Pro repository and model...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "if ENV == \"colab\":\n",
        "    # In Colab, clone the repository\n",
        "    if not os.path.exists('ml-depth-pro'):\n",
        "        print(\"Cloning Apple's Depth Pro repository...\")\n",
        "        os.system(\"git clone https://github.com/apple/ml-depth-pro.git\")\n",
        "    else:\n",
        "        print(\"Repository already exists\")\n",
        "    \n",
        "    # Change to the repository directory\n",
        "    os.chdir('ml-depth-pro')\n",
        "    print(f\"Current directory: {os.getcwd()}\")\n",
        "else:\n",
        "    # For local Jupyter, assume we're already in the right directory\n",
        "    if os.path.exists('src/depth_pro'):\n",
        "        print(\"Found depth_pro source directory\")\n",
        "    else:\n",
        "        print(\"Warning: depth_pro source not found.\")\n",
        "        print(\"Make sure you're in the ml-depth-pro directory or:\")\n",
        "        print(\"Run: git clone https://github.com/apple/ml-depth-pro.git && cd ml-depth-pro\")\n",
        "\n",
        "# Add to Python path\n",
        "sys.path.insert(0, './src')\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "print(\"Repository setup complete!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 4: Download Model Weights\n",
        "\n",
        "Downloading the pre-trained model weights (1.8GB)...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "\n",
        "def download_with_progress(url, filename):\n",
        "    \"\"\"Download file with progress bar\"\"\"\n",
        "    class TqdmUpTo(tqdm):\n",
        "        def update_to(self, b=1, bsize=1, tsize=None):\n",
        "            if tsize is not None:\n",
        "                self.total = tsize\n",
        "            self.update(b * bsize - self.n)\n",
        "    \n",
        "    with TqdmUpTo(unit='B', unit_scale=True, miniters=1, desc=filename) as t:\n",
        "        urllib.request.urlretrieve(url, filename, reporthook=t.update_to)\n",
        "\n",
        "# Download model if not already present\n",
        "model_path = 'depth_pro.pt'\n",
        "if not os.path.exists(model_path):\n",
        "    print(\"Downloading Depth Pro model weights (1.8GB)...\")\n",
        "    print(\"This may take a few minutes depending on your connection...\")\n",
        "    \n",
        "    model_url = 'https://huggingface.co/apple/depth-pro/resolve/main/depth_pro.pt'\n",
        "    download_with_progress(model_url, model_path)\n",
        "    \n",
        "    print(f\"Model downloaded! Size: {os.path.getsize(model_path) / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(f\"Model already exists! Size: {os.path.getsize(model_path) / 1e9:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 5: Install Depth Pro Package\n",
        "\n",
        "Installing the Depth Pro package...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install the depth_pro package\n",
        "print(\"Installing Depth Pro package...\")\n",
        "import subprocess\n",
        "subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-e', '.'])\n",
        "\n",
        "# Test the installation\n",
        "try:\n",
        "    import depth_pro\n",
        "    print(\"Depth Pro imported successfully!\")\n",
        "    MODEL_AVAILABLE = True\n",
        "except ImportError as e:\n",
        "    print(f\"Import failed: {e}\")\n",
        "    print(\"Trying alternative import method...\")\n",
        "    \n",
        "    # Alternative: add all necessary paths\n",
        "    import sys\n",
        "    sys.path.append('./src')\n",
        "    sys.path.append('./src/depth_pro')\n",
        "    \n",
        "    try:\n",
        "        import depth_pro\n",
        "        print(\"Alternative import successful!\")\n",
        "        MODEL_AVAILABLE = True\n",
        "    except ImportError as e2:\n",
        "        print(f\"Still failed: {e2}\")\n",
        "        MODEL_AVAILABLE = False\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 6: Create Processing Functions\n",
        "\n",
        "Setting up device selection and image processing functions...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Device selection based on environment\n",
        "def select_device():\n",
        "    \"\"\"Select the best available device\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        device_name = f\"CUDA GPU ({torch.cuda.get_device_name(0)})\"\n",
        "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "        device_name = \"Apple Silicon GPU (MPS)\"\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        device_name = \"CPU\"\n",
        "    \n",
        "    print(f\"Using device: {device_name}\")\n",
        "    return device, device_name\n",
        "\n",
        "device, device_name = select_device()\n",
        "\n",
        "# Global model variables\n",
        "model = None\n",
        "transform = None\n",
        "load_time = 0.0\n",
        "\n",
        "def load_model():\n",
        "    \"\"\"Load the Depth Pro model once\"\"\"\n",
        "    global model, transform, load_time\n",
        "    if model is None and MODEL_AVAILABLE:\n",
        "        print(\"Loading Depth Pro model...\")\n",
        "        start_time = time.time()\n",
        "        \n",
        "        try:\n",
        "            # Load model and transform\n",
        "            model, transform = depth_pro.create_model_and_transforms()\n",
        "            \n",
        "            # Move to appropriate device\n",
        "            model = model.to(device)\n",
        "            model.eval()\n",
        "            \n",
        "            load_time = time.time() - start_time\n",
        "            print(f\"Model loaded successfully in {load_time:.1f}s!\")\n",
        "            print(f\"Model moved to: {device}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model: {e}\")\n",
        "            return False\n",
        "    return model is not None\n",
        "\n",
        "print(\"Processing functions defined successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_image(image_path):\n",
        "    \"\"\"Process uploaded image and display results\"\"\"\n",
        "    if not MODEL_AVAILABLE:\n",
        "        print(\"❌ Depth Pro model not available. Please check installation.\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        # Load model if not already loaded\n",
        "        if not load_model():\n",
        "            print(\"❌ Failed to load model\")\n",
        "            return\n",
        "        \n",
        "        # Load and process image\n",
        "        if isinstance(image_path, str):\n",
        "            image = Image.open(image_path)\n",
        "        else:\n",
        "            image = image_path\n",
        "            \n",
        "        # Convert PIL image to RGB if needed\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "        \n",
        "        print(f\"📸 Processing image: {image.size}\")\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Use depth_pro's preprocessing\n",
        "        processed_image = transform(image)\n",
        "        \n",
        "        # Add batch dimension and move to device\n",
        "        if processed_image.dim() == 3:\n",
        "            processed_image = processed_image.unsqueeze(0)\n",
        "        \n",
        "        processed_image = processed_image.to(device)\n",
        "        \n",
        "        # Run inference\n",
        "        with torch.no_grad():\n",
        "            if device.type == \"mps\":\n",
        "                # Use CPU autocast for MPS to avoid potential issues\n",
        "                with torch.autocast(device_type=\"cpu\", dtype=torch.float16):\n",
        "                    prediction = model.infer(processed_image)\n",
        "            else:\n",
        "                prediction = model.infer(processed_image)\n",
        "        \n",
        "        depth = prediction[\"depth\"].cpu().numpy().squeeze()\n",
        "        focal_length = prediction[\"focallength_px\"]\n",
        "        \n",
        "        inference_time = time.time() - start_time\n",
        "        \n",
        "        # Normalize depth map for visualization (0-255)\n",
        "        depth_min, depth_max = depth.min(), depth.max()\n",
        "        depth_normalized = ((depth - depth_min) / (depth_max - depth_min) * 255).astype(np.uint8)\n",
        "        \n",
        "        # Create colormap version\n",
        "        depth_colored = cv2.applyColorMap(depth_normalized, cv2.COLORMAP_PLASMA)\n",
        "        depth_colored = cv2.cvtColor(depth_colored, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Display results\n",
        "        import matplotlib.pyplot as plt\n",
        "        \n",
        "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "        \n",
        "        # Original image\n",
        "        axes[0].imshow(image)\n",
        "        axes[0].set_title('📷 Original Image', fontsize=14, fontweight='bold')\n",
        "        axes[0].axis('off')\n",
        "        \n",
        "        # Colored depth map\n",
        "        axes[1].imshow(depth_colored)\n",
        "        axes[1].set_title('🌈 Colored Depth Map', fontsize=14, fontweight='bold')\n",
        "        axes[1].axis('off')\n",
        "        \n",
        "        # Grayscale depth map\n",
        "        axes[2].imshow(depth_normalized, cmap='gray')\n",
        "        axes[2].set_title('⚫ Grayscale Depth Map', fontsize=14, fontweight='bold')\n",
        "        axes[2].axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Print performance metrics\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"🎯 DEPTH MAP GENERATION COMPLETE!\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"🌍 Environment: {ENV.upper()}\")\n",
        "        print(f\"⚡ Device: {device_name}\")\n",
        "        print(f\"📐 Image Size: {image.width} × {image.height}\")\n",
        "        print(f\"🔍 Estimated Focal Length: {focal_length:.1f} pixels\")\n",
        "        print(f\"📏 Depth Range: {depth_min:.2f}m - {depth_max:.2f}m\")\n",
        "        print(f\"⏱️  Processing Time: {inference_time:.3f}s\")\n",
        "        print(f\"🚀 Model Load Time: {load_time:.1f}s (one-time)\")\n",
        "        print(f\"🤖 Model: Apple Depth Pro v1.0\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"💡 How to use the results:\")\n",
        "        print(\"   • Colored Version: Great for visualization and analysis\")\n",
        "        print(\"   • Grayscale Version: Use for 3D reconstruction, depth-based effects\")\n",
        "        print(\"   • Depth Values: White = closer, Black = farther\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error processing image: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "print(\"Image processing function defined successfully!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 7: Image Upload Interface\n",
        "\n",
        "Creating an interactive file upload widget...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ipywidgets import FileUpload, Button, Output, VBox, HTML\n",
        "from IPython.display import display, clear_output\n",
        "import io\n",
        "\n",
        "# Create upload widget\n",
        "print(\"📁 Setting up file upload interface...\")\n",
        "\n",
        "upload_widget = FileUpload(\n",
        "    accept='image/*',  # Accept only image files\n",
        "    multiple=False,    # Single file upload\n",
        "    description='Choose Image',\n",
        "    button_style='primary'\n",
        ")\n",
        "\n",
        "process_button = Button(\n",
        "    description='🚀 Generate Depth Map',\n",
        "    button_style='success',\n",
        "    layout={'width': '200px', 'height': '40px'}\n",
        ")\n",
        "\n",
        "output_area = Output()\n",
        "\n",
        "def on_upload_change(change):\n",
        "    \"\"\"Handle file upload\"\"\"\n",
        "    clear_output()\n",
        "    if upload_widget.value:\n",
        "        filename = list(upload_widget.value.keys())[0]\n",
        "        print(f\"📸 Image uploaded: {filename}\")\n",
        "        print(\"✅ Ready to process! Click the button below to generate depth map.\")\n",
        "    else:\n",
        "        print(\"📁 Please upload an image file (JPG, PNG, etc.)\")\n",
        "\n",
        "def on_process_click(button):\n",
        "    \"\"\"Handle process button click\"\"\"\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "        \n",
        "        if not upload_widget.value:\n",
        "            print(\"❌ Please upload an image first!\")\n",
        "            return\n",
        "            \n",
        "        # Get the uploaded file\n",
        "        filename = list(upload_widget.value.keys())[0]\n",
        "        file_content = upload_widget.value[filename]['content']\n",
        "        \n",
        "        # Convert to PIL Image\n",
        "        image = Image.open(io.BytesIO(file_content))\n",
        "        print(f\"📁 Processing uploaded file: {filename}\")\n",
        "        \n",
        "        # Process the image\n",
        "        process_image(image)\n",
        "\n",
        "# Set up event handlers\n",
        "upload_widget.observe(on_upload_change, names='value')\n",
        "process_button.on_click(on_process_click)\n",
        "\n",
        "print(\"✅ Upload interface ready!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 8: Upload Your Image\n",
        "\n",
        "Click the button below to upload an image and generate its depth map!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the upload interface\n",
        "if MODEL_AVAILABLE:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"🎯 DEPTH PRO - READY TO PROCESS IMAGES!\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"🌍 Environment: {ENV.upper()}\")\n",
        "    print(f\"⚡ Device: {device_name}\")\n",
        "    print(f\"🤖 Model Status: {'✓ Loaded' if model else '⏳ Will load on first use'}\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"📁 Upload an image below to generate its depth map!\")\n",
        "    print(\"💡 Supports: JPG, PNG, and other common image formats\")\n",
        "    print(\"🚀 Processing happens instantly in this notebook!\")\n",
        "    \n",
        "    # Display the upload widget and button\n",
        "    display(HTML(\"<h3 style='color: #4CAF50;'>📁 Step 1: Choose an Image File</h3>\"))\n",
        "    display(upload_widget)\n",
        "    \n",
        "    display(HTML(\"<h3 style='color: #2196F3;'>🚀 Step 2: Generate Depth Map</h3>\"))\n",
        "    display(process_button)\n",
        "    \n",
        "    display(HTML(\"<h3 style='color: #FF9800;'>📊 Results will appear below:</h3>\"))\n",
        "    display(output_area)\n",
        "    \n",
        "    print(\"\\n✨ Interface is ready!\")\n",
        "    print(\"👆 Click 'Choose Image' above to get started!\")\n",
        "    \n",
        "else:\n",
        "    print(\"❌ Cannot create interface - Depth Pro model not available\")\n",
        "    print(\"Please check the installation steps above and ensure all dependencies are properly installed.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
